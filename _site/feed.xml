<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.10.0">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2025-01-22T10:23:17+08:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">Madden’s Blog</title><subtitle>Write an awesome description for your new site here. You can edit this line in _config.yml. It will appear in your document head meta (for Google search results) and in your feed.xml site description.</subtitle><author><name>Madden Zhang</name></author><entry><title type="html">Stability Monitor Promtail</title><link href="http://localhost:4000/blog/stability-monitor-promtail/" rel="alternate" type="text/html" title="Stability Monitor Promtail" /><published>2025-01-14T00:00:00+08:00</published><updated>2025-01-14T00:00:00+08:00</updated><id>http://localhost:4000/blog/stability-monitor-promtail</id><content type="html" xml:base="http://localhost:4000/blog/stability-monitor-promtail/"><![CDATA[<h2 id="introduction">Introduction</h2>

<p>Promtail is an agent that collects logs from various sources and sends them to Loki for storage and querying. In this section, we will walk through the installation process of Promtail, which includes downloading the necessary files, setting up configuration, and creating a service to ensure Promtail runs continuously as a background service.</p>

<h3 id="step-1-download-promtail">Step 1: Download Promtail</h3>

<p>The first step is to download the Promtail binary from the official GitHub repository. You can find the latest release <a href="https://github.com/grafana/loki/releases">here</a>.</p>

<p>For example, to download version 3.1.2, you can execute the following command:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>wget https://github.com/grafana/loki/releases/download/v2.8.0/promtail-linux-amd64.zip
</code></pre></div></div>

<h3 id="step-2-extract-and-move-promtail-to-a-suitable-location">Step 2: Extract and Move Promtail to a Suitable Location</h3>

<p>Once the file is downloaded, extract it and move the binary to a directory included in the system’s <code class="language-plaintext highlighter-rouge">$PATH</code>, such as <code class="language-plaintext highlighter-rouge">/usr/local/bin/</code>.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>unzip promtail-linux-amd64.zip
<span class="nb">mv </span>promtail-linux-amd64 /usr/local/bin/promtail
</code></pre></div></div>

<p>Next, grant execute permissions to the Promtail binary to allow it to run:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">chmod</span> +x /usr/local/bin/promtail
</code></pre></div></div>

<h3 id="step-3-create-promtail-configuration-file">Step 3: Create Promtail Configuration File</h3>

<p>Promtail requires a configuration file that defines how logs will be collected, where they will be sent, and other parameters. Create the configuration directory and the file as follows:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">mkdir</span> <span class="nt">-p</span> /etc/promtail
vim /etc/promtail/promtail-config.yaml
</code></pre></div></div>

<p>Below is a sample configuration file you can use, which specifies the Promtail server settings, position tracking, Loki client configuration, and the log scraping setup.</p>

<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">server</span><span class="pi">:</span>
  <span class="na">http_listen_port</span><span class="pi">:</span> <span class="m">9080</span>
  <span class="na">grpc_listen_port</span><span class="pi">:</span> <span class="m">0</span>

<span class="na">positions</span><span class="pi">:</span>
  <span class="na">filename</span><span class="pi">:</span> <span class="s">/tmp/positions.yaml</span>

<span class="na">clients</span><span class="pi">:</span>
  <span class="pi">-</span> <span class="na">url</span><span class="pi">:</span> <span class="s">http://192.168.18.58:3100/loki/api/v1/push</span>
    <span class="na">batchsize</span><span class="pi">:</span> <span class="m">1048576</span>
    <span class="na">batchwait</span><span class="pi">:</span> <span class="s">2s</span>

<span class="na">scrape_configs</span><span class="pi">:</span>
  <span class="pi">-</span> <span class="na">job_name</span><span class="pi">:</span> <span class="s">your-application-name</span>
    <span class="na">static_configs</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="na">targets</span><span class="pi">:</span>
          <span class="pi">-</span> <span class="s">localhost</span>
        <span class="na">labels</span><span class="pi">:</span>
          <span class="na">job</span><span class="pi">:</span> <span class="s">your-application-name</span>
          <span class="na">__path__</span><span class="pi">:</span> <span class="s">/var/log/your-application-name/*log</span>
</code></pre></div></div>

<h3 id="step-4-create-systemd-service-file">Step 4: Create Systemd Service File</h3>

<p>In order to ensure that Promtail starts automatically during system boot and runs as a background service, we need to create a systemd service file.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>vim /etc/systemd/system/promtail.service
</code></pre></div></div>

<p>Add the following content to the file:</p>

<div class="language-ini highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nn">[Unit]</span>
<span class="py">Description</span><span class="p">=</span><span class="s">Promtail - A log collection agent for Loki</span>
<span class="py">Documentation</span><span class="p">=</span><span class="s">https://grafana.com/docs/loki/latest/clients/promtail/</span>
<span class="py">After</span><span class="p">=</span><span class="s">network.target</span>

<span class="nn">[Service]</span>
<span class="py">ExecStart</span><span class="p">=</span><span class="s">/usr/local/bin/promtail -config.file=/etc/promtail/promtail-config.yaml</span>
<span class="py">Restart</span><span class="p">=</span><span class="s">on-failure</span>
<span class="py">User</span><span class="p">=</span><span class="s">delian</span>
<span class="py">Group</span><span class="p">=</span><span class="s">delian</span>

<span class="nn">[Install]</span>
<span class="py">WantedBy</span><span class="p">=</span><span class="s">multi-user.target</span>
</code></pre></div></div>

<h3 id="step-5-start-and-enable-promtail-service">Step 5: Start and Enable Promtail Service</h3>

<p>After creating the systemd service file, reload the systemd manager to register the new service and start it. Additionally, enable it to start automatically at boot time.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>systemctl daemon-reload
systemctl start promtail
systemctl <span class="nb">enable </span>promtail
systemctl status promtail
</code></pre></div></div>

<p>The service will now run in the background, collecting and forwarding logs to Loki according to the specified configuration.</p>

<hr />

<h2 id="conclusion">Conclusion</h2>

<p>In this article, we have outlined the necessary steps to install and configure Promtail. By following these procedures, you will have a fully functional Promtail agent collecting logs and sending them to Loki, ready for real-time log monitoring.</p>]]></content><author><name>Madden Zhang</name></author><category term="Blog" /><category term="monitor" /><category term="stability" /><summary type="html"><![CDATA[Introduction Promtail is an agent that collects logs from various sources and sends them to Loki for storage and querying. In this section, we will walk through the installation process of Promtail, which includes downloading the necessary files, setting up configuration, and creating a service to ensure Promtail runs continuously as a background service. Step 1: Download Promtail The first step is to download the Promtail binary from the official GitHub repository. You can find the latest release here. For example, to download version 3.1.2, you can execute the following command: wget https://github.com/grafana/loki/releases/download/v2.8.0/promtail-linux-amd64.zip Step 2: Extract and Move Promtail to a Suitable Location Once the file is downloaded, extract it and move the binary to a directory included in the system’s $PATH, such as /usr/local/bin/. unzip promtail-linux-amd64.zip mv promtail-linux-amd64 /usr/local/bin/promtail Next, grant execute permissions to the Promtail binary to allow it to run: chmod +x /usr/local/bin/promtail Step 3: Create Promtail Configuration File Promtail requires a configuration file that defines how logs will be collected, where they will be sent, and other parameters. Create the configuration directory and the file as follows: mkdir -p /etc/promtail vim /etc/promtail/promtail-config.yaml Below is a sample configuration file you can use, which specifies the Promtail server settings, position tracking, Loki client configuration, and the log scraping setup. server: http_listen_port: 9080 grpc_listen_port: 0 positions: filename: /tmp/positions.yaml clients: - url: http://192.168.18.58:3100/loki/api/v1/push batchsize: 1048576 batchwait: 2s scrape_configs: - job_name: your-application-name static_configs: - targets: - localhost labels: job: your-application-name __path__: /var/log/your-application-name/*log Step 4: Create Systemd Service File In order to ensure that Promtail starts automatically during system boot and runs as a background service, we need to create a systemd service file. vim /etc/systemd/system/promtail.service Add the following content to the file: [Unit] Description=Promtail - A log collection agent for Loki Documentation=https://grafana.com/docs/loki/latest/clients/promtail/ After=network.target [Service] ExecStart=/usr/local/bin/promtail -config.file=/etc/promtail/promtail-config.yaml Restart=on-failure User=delian Group=delian [Install] WantedBy=multi-user.target Step 5: Start and Enable Promtail Service After creating the systemd service file, reload the systemd manager to register the new service and start it. Additionally, enable it to start automatically at boot time. systemctl daemon-reload systemctl start promtail systemctl enable promtail systemctl status promtail The service will now run in the background, collecting and forwarding logs to Loki according to the specified configuration. Conclusion In this article, we have outlined the necessary steps to install and configure Promtail. By following these procedures, you will have a fully functional Promtail agent collecting logs and sending them to Loki, ready for real-time log monitoring.]]></summary></entry><entry><title type="html">Stability Monitor Loki</title><link href="http://localhost:4000/blog/stability-monitor-loki/" rel="alternate" type="text/html" title="Stability Monitor Loki" /><published>2025-01-11T00:00:00+08:00</published><updated>2025-01-11T00:00:00+08:00</updated><id>http://localhost:4000/blog/stability-monitor-loki</id><content type="html" xml:base="http://localhost:4000/blog/stability-monitor-loki/"><![CDATA[<h2 id="install-loki">Install Loki</h2>

<p>To install <strong>Loki</strong> version <strong>3.1.2</strong> on a Linux system, follow the steps below. Loki is an open-source log aggregation system developed by Grafana Labs, and you can install it using either pre-built binaries, Docker, or through package managers. We’ll use pre-built binaries for this guide.</p>

<h3 id="step-1-download-the-loki-binary">Step 1: Download the Loki Binary</h3>

<p>Go to the <a href="https://github.com/grafana/loki/releases">Loki GitHub releases page</a> and find version <strong>3.1.2</strong>. Or use <code class="language-plaintext highlighter-rouge">wget</code> to directly download the binary:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>wget https://github.com/grafana/loki/releases/download/v3.1.2/loki-linux-amd64.zip
</code></pre></div></div>

<p>Once downloaded, extract the <code class="language-plaintext highlighter-rouge">.zip</code> file:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>unzip loki-linux-amd64.zip
</code></pre></div></div>

<p>This will create a folder containing the Loki binary (<code class="language-plaintext highlighter-rouge">loki-linux-amd64</code>).</p>

<h3 id="step-2-move-loki-to-a-system-directory">Step 2: Move Loki to a System Directory</h3>

<p>Move the extracted binary to a directory in your PATH (e.g., <code class="language-plaintext highlighter-rouge">/usr/local/bin</code>):</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">mv </span>loki-linux-amd64 /usr/local/bin/loki
</code></pre></div></div>

<p>Ensure the binary is executable:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">chmod</span> +x /usr/local/bin/loki
</code></pre></div></div>

<h3 id="step-3-create-a-configuration-file-optional">Step 3: Create a Configuration File (Optional)</h3>

<p>Create a directory for Loki configuration and add the <code class="language-plaintext highlighter-rouge">local-config.yaml</code> file:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">mkdir</span> <span class="nt">-p</span> /etc/loki
vim /etc/loki/local-config.yaml
</code></pre></div></div>

<p>The content for <code class="language-plaintext highlighter-rouge">local-config.yaml</code>:</p>

<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">auth_enabled</span><span class="pi">:</span> <span class="no">false</span>

<span class="na">server</span><span class="pi">:</span>
  <span class="na">http_listen_port</span><span class="pi">:</span> <span class="m">3100</span>
  <span class="na">grpc_listen_port</span><span class="pi">:</span> <span class="m">9095</span>

<span class="na">common</span><span class="pi">:</span>
  <span class="na">path_prefix</span><span class="pi">:</span> <span class="s">/loki/data</span>  

<span class="na">storage_config</span><span class="pi">:</span>
  <span class="na">boltdb_shipper</span><span class="pi">:</span>
    <span class="na">active_index_directory</span><span class="pi">:</span> <span class="s">/loki/index</span>
    <span class="na">cache_location</span><span class="pi">:</span> <span class="s">/loki/cache</span>
    <span class="na">resync_interval</span><span class="pi">:</span> <span class="s">10m</span>
  <span class="na">filesystem</span><span class="pi">:</span>
    <span class="na">directory</span><span class="pi">:</span> <span class="s">/loki/chunks</span>

<span class="na">limits_config</span><span class="pi">:</span>
  <span class="na">retention_period</span><span class="pi">:</span> <span class="s">90d</span>
  <span class="na">allow_structured_metadata</span><span class="pi">:</span> <span class="no">false</span> 

<span class="na">schema_config</span><span class="pi">:</span>
  <span class="na">configs</span><span class="pi">:</span>
    <span class="pi">-</span> <span class="na">from</span><span class="pi">:</span> <span class="s">2020-10-21</span>
      <span class="na">store</span><span class="pi">:</span> <span class="s">boltdb-shipper</span>
      <span class="na">object_store</span><span class="pi">:</span> <span class="s">filesystem</span>
      <span class="na">schema</span><span class="pi">:</span> <span class="s">v13</span>
      <span class="na">index</span><span class="pi">:</span>
        <span class="na">prefix</span><span class="pi">:</span> <span class="s">index_</span>
        <span class="na">period</span><span class="pi">:</span> <span class="s">24h</span>  

<span class="na">compactor</span><span class="pi">:</span>
  <span class="na">working_directory</span><span class="pi">:</span> <span class="s">/loki/compactor</span> 

<span class="na">table_manager</span><span class="pi">:</span>
  <span class="na">retention_deletes_enabled</span><span class="pi">:</span> <span class="no">true</span>
  <span class="na">retention_period</span><span class="pi">:</span> <span class="s">90d</span>

<span class="na">ingester</span><span class="pi">:</span>
  <span class="na">lifecycler</span><span class="pi">:</span>
    <span class="na">ring</span><span class="pi">:</span>
      <span class="na">kvstore</span><span class="pi">:</span>
        <span class="na">store</span><span class="pi">:</span> <span class="s">memberlist</span>
      <span class="na">replication_factor</span><span class="pi">:</span> <span class="m">1</span>
  <span class="na">chunk_target_size</span><span class="pi">:</span> <span class="s">1048576</span>  
  <span class="na">max_chunk_age</span><span class="pi">:</span> <span class="s">1h</span> 

<span class="na">memberlist</span><span class="pi">:</span>
  <span class="na">join_members</span><span class="pi">:</span> <span class="pi">[]</span> 
</code></pre></div></div>

<h3 id="step-4-configure-log-file-storage">Step 4: Configure Log File Storage</h3>

<p>Define storage directories for Loki logs:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">mkdir</span> <span class="nt">-p</span> /var/loki/chunks /var/loki/index /var/loki/cache /var/loki/compactor
<span class="nb">chown</span> <span class="nt">-R</span> loki:loki /var/loki
</code></pre></div></div>

<p>Create the Loki systemd service file:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>vim /etc/systemd/system/loki.service
</code></pre></div></div>

<p>Add the following content:</p>

<div class="language-ini highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nn">[Unit]</span>
<span class="py">Description</span><span class="p">=</span><span class="s">Loki</span>
<span class="py">Documentation</span><span class="p">=</span><span class="s">https://grafana.com/docs/loki/latest/</span>
<span class="py">After</span><span class="p">=</span><span class="s">network.target</span>

<span class="nn">[Service]</span>
<span class="py">ExecStart</span><span class="p">=</span><span class="s">/usr/local/bin/loki -config.file=/etc/loki/local-config.yaml</span>
<span class="py">Restart</span><span class="p">=</span><span class="s">on-failure</span>
<span class="py">User</span><span class="p">=</span><span class="s">delian</span>
<span class="py">Group</span><span class="p">=</span><span class="s">delian</span>

<span class="nn">[Install]</span>
<span class="py">WantedBy</span><span class="p">=</span><span class="s">multi-user.target</span>
</code></pre></div></div>

<h3 id="step-5-start-loki-service">Step 5: Start Loki Service</h3>

<p>Reload systemd, enable and start the Loki service:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>systemctl daemon-reload
systemctl <span class="nb">enable </span>loki
systemctl start loki
systemctl status loki
</code></pre></div></div>

<p>To monitor logs:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>journalctl <span class="nt">-u</span> loki <span class="nt">-f</span>
</code></pre></div></div>

<p>Verify the Loki version:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>loki <span class="nt">--version</span>
</code></pre></div></div>

<h2 id="conclusion">Conclusion</h2>

<p>By following the above steps, you should have Loki installed and running with the necessary configurations for log aggregation. You can now proceed to integrate Loki with other components like Promtail, Grafana, etc., for a complete logging solution.</p>]]></content><author><name>Madden Zhang</name></author><category term="Blog" /><category term="monitor" /><category term="stability" /><summary type="html"><![CDATA[Install Loki To install Loki version 3.1.2 on a Linux system, follow the steps below. Loki is an open-source log aggregation system developed by Grafana Labs, and you can install it using either pre-built binaries, Docker, or through package managers. We’ll use pre-built binaries for this guide. Step 1: Download the Loki Binary Go to the Loki GitHub releases page and find version 3.1.2. Or use wget to directly download the binary: wget https://github.com/grafana/loki/releases/download/v3.1.2/loki-linux-amd64.zip Once downloaded, extract the .zip file: unzip loki-linux-amd64.zip This will create a folder containing the Loki binary (loki-linux-amd64). Step 2: Move Loki to a System Directory Move the extracted binary to a directory in your PATH (e.g., /usr/local/bin): mv loki-linux-amd64 /usr/local/bin/loki Ensure the binary is executable: chmod +x /usr/local/bin/loki Step 3: Create a Configuration File (Optional) Create a directory for Loki configuration and add the local-config.yaml file: mkdir -p /etc/loki vim /etc/loki/local-config.yaml The content for local-config.yaml: auth_enabled: false server: http_listen_port: 3100 grpc_listen_port: 9095 common: path_prefix: /loki/data storage_config: boltdb_shipper: active_index_directory: /loki/index cache_location: /loki/cache resync_interval: 10m filesystem: directory: /loki/chunks limits_config: retention_period: 90d allow_structured_metadata: false schema_config: configs: - from: 2020-10-21 store: boltdb-shipper object_store: filesystem schema: v13 index: prefix: index_ period: 24h compactor: working_directory: /loki/compactor table_manager: retention_deletes_enabled: true retention_period: 90d ingester: lifecycler: ring: kvstore: store: memberlist replication_factor: 1 chunk_target_size: 1048576 max_chunk_age: 1h memberlist: join_members: [] Step 4: Configure Log File Storage Define storage directories for Loki logs: mkdir -p /var/loki/chunks /var/loki/index /var/loki/cache /var/loki/compactor chown -R loki:loki /var/loki Create the Loki systemd service file: vim /etc/systemd/system/loki.service Add the following content: [Unit] Description=Loki Documentation=https://grafana.com/docs/loki/latest/ After=network.target [Service] ExecStart=/usr/local/bin/loki -config.file=/etc/loki/local-config.yaml Restart=on-failure User=delian Group=delian [Install] WantedBy=multi-user.target Step 5: Start Loki Service Reload systemd, enable and start the Loki service: systemctl daemon-reload systemctl enable loki systemctl start loki systemctl status loki To monitor logs: journalctl -u loki -f Verify the Loki version: loki --version Conclusion By following the above steps, you should have Loki installed and running with the necessary configurations for log aggregation. You can now proceed to integrate Loki with other components like Promtail, Grafana, etc., for a complete logging solution.]]></summary></entry><entry><title type="html">Stability Monitor Prometheus</title><link href="http://localhost:4000/blog/stability-monitor-prometheus/" rel="alternate" type="text/html" title="Stability Monitor Prometheus" /><published>2025-01-11T00:00:00+08:00</published><updated>2025-01-11T00:00:00+08:00</updated><id>http://localhost:4000/blog/stability-monitor-prometheus</id><content type="html" xml:base="http://localhost:4000/blog/stability-monitor-prometheus/"><![CDATA[<h2 id="background">Background</h2>
<p>A significant part of system stability is supported by monitoring. Large companies usually have well-established monitoring and operations teams to build the monitoring infrastructure. From a layered perspective, monitoring generally includes the following aspects:</p>
<table>
  <thead>
    <tr>
      <th>Monitoring Dimension</th>
      <th>Middleware Selection</th>
      <th>Reason for Selection</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Metric Monitoring</td>
      <td>Prometheus + Grafana</td>
      <td>Supports multiple Exporters, rich ecosystem, easy to configure alerts and visualizations</td>
    </tr>
    <tr>
      <td>Log Monitoring</td>
      <td>Loki + Promtail/Fluent Bit</td>
      <td>Lightweight log aggregation solution, seamlessly integrates with Grafana</td>
    </tr>
    <tr>
      <td>Distributed Tracing</td>
      <td>OpenTelemetry + Jaeger</td>
      <td>Open standard for distributed tracing, supports multiple languages</td>
    </tr>
    <tr>
      <td>Database Monitoring</td>
      <td>Exporter (e.g., MySQL Exporter)</td>
      <td>Prometheus maintained by official or community, supports mainstream databases</td>
    </tr>
    <tr>
      <td>Network Monitoring</td>
      <td>Blackbox Exporter</td>
      <td>Supports multi-protocol health checks like HTTP, TCP</td>
    </tr>
    <tr>
      <td>Alerting and Notification</td>
      <td>Alertmanager</td>
      <td>Supports multi-channel notifications (email, Slack, Webhook, SMS, etc.)</td>
    </tr>
  </tbody>
</table>

<h2 id="best-practices-for-selection">Best Practices for Selection</h2>
<p>Small and medium-sized companies can quickly build a monitoring system that suits their business characteristics. Prometheus has already become the standard for real-time monitoring. We can quickly set up our own monitoring system based on Prometheus:</p>
<table>
  <thead>
    <tr>
      <th>Monitoring Dimension</th>
      <th>Middleware Selection</th>
      <th>Reason for Selection</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Metric Monitoring</td>
      <td>Prometheus + Grafana</td>
      <td>Supports multiple Exporters, rich ecosystem, easy to configure alerts and visualizations</td>
    </tr>
    <tr>
      <td>Log Monitoring</td>
      <td>Loki + Promtail/Fluent Bit</td>
      <td>Lightweight log aggregation solution, seamlessly integrates with Grafana</td>
    </tr>
    <tr>
      <td>Distributed Tracing</td>
      <td>OpenTelemetry + Jaeger</td>
      <td>Open standard for distributed tracing, supports multiple languages</td>
    </tr>
    <tr>
      <td>Database Monitoring</td>
      <td>Exporter (e.g., MySQL Exporter, Redis Exporter)</td>
      <td>Prometheus maintained by official or community, supports mainstream databases</td>
    </tr>
    <tr>
      <td>Network Monitoring</td>
      <td>Blackbox Exporter</td>
      <td>Supports multi-protocol health checks like HTTP, TCP</td>
    </tr>
    <tr>
      <td>Alerting and Notification</td>
      <td>Alertmanager</td>
      <td>Supports multi-channel notifications (email, Slack, Webhook, SMS, etc.)</td>
    </tr>
  </tbody>
</table>

<h2 id="system-architecture-design">System Architecture Design</h2>
<div class="mermaid">
  graph TD;
    A[Prometheus] --&gt; B[Exporters]
    A --&gt; C[Blackbox Exporter]
    A --&gt; D[Alertmanager]
    B --&gt; E[Grafana]
    C --&gt; E
    D --&gt; E
    F[Loki] --&gt; G[Promtail/Fluent Bit]
    G --&gt; E
    H[OpenTelemetry] --&gt; I[Jaeger]
    I --&gt; E
</div>

<h2 id="defining-refined-monitoring-metrics">Defining Refined Monitoring Metrics</h2>
<h3 id="jvm-monitoring">JVM Monitoring</h3>

<p>JVM monitoring is used to track important JVM metrics, including GC (Garbage Collection) instant metrics, heap memory metrics, non-heap memory metrics, metaspace metrics, direct buffer metrics, JVM thread count, etc. This section introduces JVM monitoring and how to view JVM monitoring metrics.</p>

<p>JVM monitoring can track the following metrics:</p>

<ul>
  <li>GC (Garbage Collection) instant and cumulative details
    <ul>
      <li>FullGC count</li>
      <li>YoungGC count</li>
      <li>FullGC duration</li>
      <li>YoungGC duration</li>
    </ul>
  </li>
  <li>Heap Memory Details
    <ul>
      <li>Total heap memory</li>
      <li>Old generation heap memory size</li>
      <li>Young generation Survivor area size</li>
      <li>Young generation Eden area size</li>
    </ul>
  </li>
  <li>
    <p>Metaspace</p>

    <p>Metaspace size</p>
  </li>
  <li>Non-Heap Memory
    <ul>
      <li>Maximum non-heap memory size</li>
      <li>Used non-heap memory size</li>
    </ul>
  </li>
  <li>Direct Buffer
    <ul>
      <li>Total DirectBuffer size (bytes)</li>
      <li>Used DirectBuffer size (bytes)</li>
    </ul>
  </li>
  <li>JVM Thread Count
    <ul>
      <li>Total number of threads</li>
      <li>Number of deadlocked threads</li>
      <li>Number of newly created threads</li>
      <li>Number of blocked threads</li>
      <li>Number of runnable threads</li>
      <li>Number of terminated threads</li>
      <li>Number of threads in timed wait</li>
      <li>Number of threads in waiting state</li>
    </ul>
  </li>
</ul>

<div class="mermaid">
mindmap
  root((Java Process Memory Usage))
    JVM Memory
      Heap Memory
        Young Generation
        Old Generation
      Non-Heap Memory
        Metaspace
        Compressed Class Space
        Virtual Machine Thread Stack
        Native Thread Stack
        Code Cache
        Direct Buffers
    Non-JVM Memory
      Native Runtime Libraries
      JNI Native Code
</div>

<h3 id="host-monitoring">Host Monitoring</h3>

<p>Host monitoring tracks various metrics such as CPU, memory, disk, load, network traffic, and network packet metrics. This section introduces host monitoring and how to view host monitoring metrics.</p>

<p>Host monitoring can track the following metrics:</p>

<ul>
  <li>CPU
    <ul>
      <li>Total CPU usage</li>
      <li>System CPU usage</li>
      <li>User CPU usage</li>
      <li>CPU usage waiting for I/O completion</li>
    </ul>
  </li>
  <li>Physical Memory
    <ul>
      <li>Total system memory</li>
      <li>Free system memory</li>
      <li>Used system memory</li>
      <li>Memory in PageCache</li>
      <li>Memory in BufferCache</li>
    </ul>
  </li>
  <li>Disk
    <ul>
      <li>Total system disk size</li>
      <li>Free system disk size</li>
      <li>Used system disk size</li>
    </ul>
  </li>
  <li>
    <p>Load</p>

    <p>System load average</p>
  </li>
  <li>Network Traffic
    <ul>
      <li>Network received bytes</li>
      <li>Network sent bytes</li>
    </ul>
  </li>
  <li>Network Packets
    <ul>
      <li>Number of received packets per minute</li>
      <li>Number of sent packets per minute</li>
      <li>Number of network errors per minute</li>
      <li>Number of dropped packets per minute</li>
    </ul>
  </li>
</ul>

<h3 id="sql-call-analysis"><strong>SQL Call Analysis</strong></h3>

<p>View SQL call analysis to understand SQL call patterns in applications.</p>

<h3 id="error-code-monitoring">Error Code Monitoring</h3>

<p>For core business systems, such as payment systems, error code monitoring is essential.</p>

<p>Here’s how to install Prometheus step by step in English. If you use the docker you can use this to setup, this is the easy way. <a href="https://github.com/maddenmanel/springboot-prometheus-grafana">springboot-promethenus-grafana</a>.</p>

<h3 id="install-article-list">Install Article list</h3>

<ul>
  <li><a href="/tool/stability-monitor-loki/">Install Loki with Prometheus</a></li>
  <li><a href="/tool/stability-monitor-promtail/">Install Promtail with Prometheus</a></li>
</ul>

<script type="module">
  import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.esm.min.mjs';
  mermaid.initialize({ startOnLoad: true });
</script>]]></content><author><name>Madden Zhang</name></author><category term="Blog" /><category term="monitor" /><category term="stability" /><summary type="html"><![CDATA[Background A significant part of system stability is supported by monitoring. Large companies usually have well-established monitoring and operations teams to build the monitoring infrastructure. From a layered perspective, monitoring generally includes the following aspects: Monitoring Dimension Middleware Selection Reason for Selection Metric Monitoring Prometheus + Grafana Supports multiple Exporters, rich ecosystem, easy to configure alerts and visualizations Log Monitoring Loki + Promtail/Fluent Bit Lightweight log aggregation solution, seamlessly integrates with Grafana Distributed Tracing OpenTelemetry + Jaeger Open standard for distributed tracing, supports multiple languages Database Monitoring Exporter (e.g., MySQL Exporter) Prometheus maintained by official or community, supports mainstream databases Network Monitoring Blackbox Exporter Supports multi-protocol health checks like HTTP, TCP Alerting and Notification Alertmanager Supports multi-channel notifications (email, Slack, Webhook, SMS, etc.) Best Practices for Selection Small and medium-sized companies can quickly build a monitoring system that suits their business characteristics. Prometheus has already become the standard for real-time monitoring. We can quickly set up our own monitoring system based on Prometheus: Monitoring Dimension Middleware Selection Reason for Selection Metric Monitoring Prometheus + Grafana Supports multiple Exporters, rich ecosystem, easy to configure alerts and visualizations Log Monitoring Loki + Promtail/Fluent Bit Lightweight log aggregation solution, seamlessly integrates with Grafana Distributed Tracing OpenTelemetry + Jaeger Open standard for distributed tracing, supports multiple languages Database Monitoring Exporter (e.g., MySQL Exporter, Redis Exporter) Prometheus maintained by official or community, supports mainstream databases Network Monitoring Blackbox Exporter Supports multi-protocol health checks like HTTP, TCP Alerting and Notification Alertmanager Supports multi-channel notifications (email, Slack, Webhook, SMS, etc.) System Architecture Design graph TD; A[Prometheus] --&gt; B[Exporters] A --&gt; C[Blackbox Exporter] A --&gt; D[Alertmanager] B --&gt; E[Grafana] C --&gt; E D --&gt; E F[Loki] --&gt; G[Promtail/Fluent Bit] G --&gt; E H[OpenTelemetry] --&gt; I[Jaeger] I --&gt; E Defining Refined Monitoring Metrics JVM Monitoring JVM monitoring is used to track important JVM metrics, including GC (Garbage Collection) instant metrics, heap memory metrics, non-heap memory metrics, metaspace metrics, direct buffer metrics, JVM thread count, etc. This section introduces JVM monitoring and how to view JVM monitoring metrics. JVM monitoring can track the following metrics: GC (Garbage Collection) instant and cumulative details FullGC count YoungGC count FullGC duration YoungGC duration Heap Memory Details Total heap memory Old generation heap memory size Young generation Survivor area size Young generation Eden area size Metaspace Metaspace size Non-Heap Memory Maximum non-heap memory size Used non-heap memory size Direct Buffer Total DirectBuffer size (bytes) Used DirectBuffer size (bytes) JVM Thread Count Total number of threads Number of deadlocked threads Number of newly created threads Number of blocked threads Number of runnable threads Number of terminated threads Number of threads in timed wait Number of threads in waiting state mindmap root((Java Process Memory Usage)) JVM Memory Heap Memory Young Generation Old Generation Non-Heap Memory Metaspace Compressed Class Space Virtual Machine Thread Stack Native Thread Stack Code Cache Direct Buffers Non-JVM Memory Native Runtime Libraries JNI Native Code Host Monitoring Host monitoring tracks various metrics such as CPU, memory, disk, load, network traffic, and network packet metrics. This section introduces host monitoring and how to view host monitoring metrics. Host monitoring can track the following metrics: CPU Total CPU usage System CPU usage User CPU usage CPU usage waiting for I/O completion Physical Memory Total system memory Free system memory Used system memory Memory in PageCache Memory in BufferCache Disk Total system disk size Free system disk size Used system disk size Load System load average Network Traffic Network received bytes Network sent bytes Network Packets Number of received packets per minute Number of sent packets per minute Number of network errors per minute Number of dropped packets per minute SQL Call Analysis View SQL call analysis to understand SQL call patterns in applications. Error Code Monitoring For core business systems, such as payment systems, error code monitoring is essential. Here’s how to install Prometheus step by step in English. If you use the docker you can use this to setup, this is the easy way. springboot-promethenus-grafana. Install Article list Install Loki with Prometheus Install Promtail with Prometheus]]></summary></entry><entry><title type="html">Welcome to Jekyll!</title><link href="http://localhost:4000/blog/welcome-to-jekyll/" rel="alternate" type="text/html" title="Welcome to Jekyll!" /><published>2019-04-19T03:34:30+08:00</published><updated>2019-04-19T03:34:30+08:00</updated><id>http://localhost:4000/blog/welcome-to-jekyll</id><content type="html" xml:base="http://localhost:4000/blog/welcome-to-jekyll/"><![CDATA[<p>You’ll find this post in your <code class="language-plaintext highlighter-rouge">_posts</code> directory. Go ahead and edit it and re-build the site to see your changes. You can rebuild the site in many different ways, but the most common way is to run <code class="language-plaintext highlighter-rouge">jekyll serve</code>, which launches a web server and auto-regenerates your site when a file is updated.</p>

<p>To add new posts, simply add a file in the <code class="language-plaintext highlighter-rouge">_posts</code> directory that follows the convention <code class="language-plaintext highlighter-rouge">YYYY-MM-DD-name-of-post.ext</code> and includes the necessary front matter. Take a look at the source for this post to get an idea about how it works.</p>

<p>Jekyll also offers powerful support for code snippets:</p>

<div class="language-ruby highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">print_hi</span><span class="p">(</span><span class="nb">name</span><span class="p">)</span>
  <span class="nb">puts</span> <span class="s2">"Hi, </span><span class="si">#{</span><span class="nb">name</span><span class="si">}</span><span class="s2">"</span>
<span class="k">end</span>
<span class="n">print_hi</span><span class="p">(</span><span class="s1">'Tom'</span><span class="p">)</span>
<span class="c1">#=&gt; prints 'Hi, Tom' to STDOUT.</span>
</code></pre></div></div>

<p>Check out the <a href="https://jekyllrb.com/docs/home">Jekyll docs</a> for more info on how to get the most out of Jekyll. File all bugs/feature requests at <a href="https://github.com/jekyll/jekyll">Jekyll’s GitHub repo</a>. If you have questions, you can ask them on <a href="https://talk.jekyllrb.com/">Jekyll Talk</a>.</p>]]></content><author><name>Madden Zhang</name></author><category term="blog" /><category term="Jekyll" /><category term="update" /><summary type="html"><![CDATA[You’ll find this post in your _posts directory. Go ahead and edit it and re-build the site to see your changes. You can rebuild the site in many different ways, but the most common way is to run jekyll serve, which launches a web server and auto-regenerates your site when a file is updated.]]></summary></entry><entry><title type="html">Distribute Design Kafka</title><link href="http://localhost:4000/blog/distribute-design-kafka/" rel="alternate" type="text/html" title="Distribute Design Kafka" /><published>2018-07-11T00:00:00+08:00</published><updated>2018-07-11T00:00:00+08:00</updated><id>http://localhost:4000/blog/distribute-design-kafka</id><content type="html" xml:base="http://localhost:4000/blog/distribute-design-kafka/"><![CDATA[<h2 id="introduction">Introduction</h2>

<p>Apache Kafka, initially developed by LinkedIn, is a distributed messaging system that has become a core component of Apache’s ecosystem. Written in Scala, Kafka is renowned for its scalability and high throughput. It is widely used in big data platforms and integrates seamlessly with distributed processing systems like Cloudera, Apache Storm, and Apache Spark.</p>

<p>As a commercially viable middleware, Kafka’s message reliability is of utmost importance. How can we ensure the precise transmission, accurate storage, and correct consumption of messages? This article dives into Kafka’s architecture and reliability mechanisms, including its storage structure, replication, and synchronization principles.</p>

<h2 id="key-terminologies">Key Terminologies</h2>

<table>
  <thead>
    <tr>
      <th>Term</th>
      <th>Explanation</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Broker</td>
      <td>A Kafka node that handles message processing. Multiple brokers form a Kafka cluster.</td>
    </tr>
    <tr>
      <td>Topic</td>
      <td>Kafka uses topics to categorize messages. Every message published to Kafka needs a topic.</td>
    </tr>
    <tr>
      <td>Producer</td>
      <td>The client that sends messages to Kafka brokers.</td>
    </tr>
    <tr>
      <td>Consumer</td>
      <td>The client that reads messages from Kafka brokers.</td>
    </tr>
    <tr>
      <td>Consumer Group</td>
      <td>A group of consumers, where each message can only be consumed by one consumer within the group.</td>
    </tr>
    <tr>
      <td>Partition</td>
      <td>The physical division of a topic. A topic can have multiple partitions.</td>
    </tr>
    <tr>
      <td>Segment</td>
      <td>A partition is divided into multiple segments.</td>
    </tr>
    <tr>
      <td>Offset</td>
      <td>A unique identifier for messages within a partition. Each message has a sequential offset number.</td>
    </tr>
  </tbody>
</table>

<h2 id="kafkas-storage-mechanism">Kafka’s Storage Mechanism</h2>

<p>Kafka’s storage mechanism can be understood from four aspects:</p>

<h3 id="partition-distribution-in-topics">Partition Distribution in Topics</h3>

<p>In a Kafka cluster, each partition of a topic is stored across multiple brokers.<br />
For instance, consider a setup where a topic like report_push has four partitions.<br />
Kafka partitions are stored as directories with the naming convention: <code class="language-plaintext highlighter-rouge">topic-name-partition-index</code>.</p>

<h3 id="partition-file-storage">Partition File Storage</h3>

<p>Each partition is stored as a series of segments, which are essentially large files.<br />
Each segment file consists of two parts: an index file (.index) and a data file (.log).</p>

<div class="mermaid">
graph TD
  A[Producer] --&gt;|Pushes data| B[Kafka Broker]
  B --&gt;|Distributes messages| C[Partition]
  C --&gt; D[Segment]
  D --&gt; E[Message]
</div>

<h3 id="segment-storage-structure">Segment Storage Structure</h3>

<p>A segment file includes index and data files. The index file stores metadata, while the data file stores actual messages.<br />
Segment files are named based on the last message’s offset, helping Kafka efficiently locate data.</p>

<div class="mermaid">
graph TD
  A[Segment] --&gt; B[Index File]
  A --&gt; C[Data File]
  B --&gt; D[Message Metadata]
  C --&gt; E[Message Data]
</div>

<h3 id="locating-messages-using-offsets">Locating Messages Using Offsets</h3>

<p>Kafka uses the offset to locate messages within the partition. Each message has an offset number, which is used to efficiently find and retrieve it.</p>

<div class="mermaid">
graph TD
  A[Partition] --&gt; B[Message with Offset]
  B --&gt; C[Index File Lookup]
  C --&gt; D[Data File Access]
</div>

<h2 id="kafkas-internal-architecture">Kafka’s Internal Architecture</h2>

<p>The internal architecture of Kafka includes the following core components:</p>

<ul>
  <li><strong>Producer:</strong> Sends messages to the Kafka cluster.</li>
  <li><strong>Broker:</strong> Handles messages and stores partitions.</li>
  <li><strong>Consumer:</strong> Pulls messages from the Kafka cluster.</li>
  <li><strong>Zookeeper:</strong> Manages Kafka’s cluster state and coordinates leader election and partition management.</li>
</ul>

<div class="mermaid">
graph TD
  A[Producer] --&gt; B[Broker]
  B --&gt; C[Partition]
  C --&gt; D[Consumer]
  D --&gt; E[Zookeeper]
</div>

<h2 id="ensuring-high-reliability">Ensuring High Reliability</h2>

<p>Kafka’s high reliability stems from its robust replication mechanism, which ensures message availability even in the event of broker failures.</p>

<h3 id="data-synchronization">Data Synchronization</h3>

<p>Kafka introduced replication in version 0.8 to mitigate data loss during broker failures. Each partition has multiple replicas, with one replica acting as the leader and others as followers.</p>

<div class="mermaid">
graph TD
  A[Producer] --&gt; B[Leader Partition]
  B --&gt; C[Follower 1]
  B --&gt; D[Follower 2]
  C --&gt; E[Write Sync]
  D --&gt; E[Write Sync]
</div>

<h3 id="replica-placement-strategy">Replica Placement Strategy</h3>

<p>Kafka distributes replicas across multiple brokers to balance load. It employs a modular arithmetic approach to determine where to place replicas.</p>

<div class="mermaid">
graph TD
  A[Broker 1] --&gt; B[Partition 1 Replica 1]
  A[Broker 2] --&gt; C[Partition 1 Replica 2]
  A[Broker 3] --&gt; D[Partition 1 Replica 3]
</div>

<h3 id="synchronization-strategy">Synchronization Strategy</h3>

<p>Producers only send messages to the leader of a partition. After the leader writes the message, followers synchronize with the leader.</p>

<div class="mermaid">
graph TD
  A[Producer] --&gt; B[Leader]
  B --&gt; C[Follower 1]
  B --&gt; D[Follower 2]
  C --&gt; E[ACK]
  D --&gt; E[ACK]
  E --&gt; F[Leader Commit]
</div>

<h3 id="leader-election">Leader Election</h3>

<p>Kafka’s leader election is managed by Zookeeper, which uses a distributed lock mechanism to ensure that only one replica becomes the leader of a partition.</p>

<div class="mermaid">
graph TD
  A[Zookeeper] --&gt; B[Partition 1 Leader Election]
  B --&gt; C[Follower 1]
  B --&gt; D[Follower 2]
  C --&gt; E[Leader Role]
  D --&gt; F[Follower Role]
</div>

<h2 id="conclusion">Conclusion</h2>

<p>Kafka’s architecture ensures high reliability, scalability, and performance, making it a vital tool in modern data processing. With its sophisticated replication mechanism, partitioning strategies, and efficient storage system, Kafka delivers message guarantees and fault tolerance that are crucial in large-scale distributed systems.</p>

<p>The above content outlines Kafka’s design and operational principles, integrating your provided article with added explanations and visualization using Mermaid diagrams. This should give a clear and comprehensive understanding of Kafka’s message storage, architecture, and reliability features.</p>

<script type="module">
  import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.esm.min.mjs';
  mermaid.initialize({ startOnLoad: true });
</script>]]></content><author><name>Madden Zhang</name></author><category term="Blog" /><category term="distribute" /><category term="kafka" /><summary type="html"><![CDATA[Introduction Apache Kafka, initially developed by LinkedIn, is a distributed messaging system that has become a core component of Apache’s ecosystem. Written in Scala, Kafka is renowned for its scalability and high throughput. It is widely used in big data platforms and integrates seamlessly with distributed processing systems like Cloudera, Apache Storm, and Apache Spark. As a commercially viable middleware, Kafka’s message reliability is of utmost importance. How can we ensure the precise transmission, accurate storage, and correct consumption of messages? This article dives into Kafka’s architecture and reliability mechanisms, including its storage structure, replication, and synchronization principles. Key Terminologies Term Explanation Broker A Kafka node that handles message processing. Multiple brokers form a Kafka cluster. Topic Kafka uses topics to categorize messages. Every message published to Kafka needs a topic. Producer The client that sends messages to Kafka brokers. Consumer The client that reads messages from Kafka brokers. Consumer Group A group of consumers, where each message can only be consumed by one consumer within the group. Partition The physical division of a topic. A topic can have multiple partitions. Segment A partition is divided into multiple segments. Offset A unique identifier for messages within a partition. Each message has a sequential offset number. Kafka’s Storage Mechanism Kafka’s storage mechanism can be understood from four aspects: Partition Distribution in Topics In a Kafka cluster, each partition of a topic is stored across multiple brokers. For instance, consider a setup where a topic like report_push has four partitions. Kafka partitions are stored as directories with the naming convention: topic-name-partition-index. Partition File Storage Each partition is stored as a series of segments, which are essentially large files. Each segment file consists of two parts: an index file (.index) and a data file (.log). graph TD A[Producer] --&gt;|Pushes data| B[Kafka Broker] B --&gt;|Distributes messages| C[Partition] C --&gt; D[Segment] D --&gt; E[Message] Segment Storage Structure A segment file includes index and data files. The index file stores metadata, while the data file stores actual messages. Segment files are named based on the last message’s offset, helping Kafka efficiently locate data. graph TD A[Segment] --&gt; B[Index File] A --&gt; C[Data File] B --&gt; D[Message Metadata] C --&gt; E[Message Data] Locating Messages Using Offsets Kafka uses the offset to locate messages within the partition. Each message has an offset number, which is used to efficiently find and retrieve it. graph TD A[Partition] --&gt; B[Message with Offset] B --&gt; C[Index File Lookup] C --&gt; D[Data File Access] Kafka’s Internal Architecture The internal architecture of Kafka includes the following core components: Producer: Sends messages to the Kafka cluster. Broker: Handles messages and stores partitions. Consumer: Pulls messages from the Kafka cluster. Zookeeper: Manages Kafka’s cluster state and coordinates leader election and partition management. graph TD A[Producer] --&gt; B[Broker] B --&gt; C[Partition] C --&gt; D[Consumer] D --&gt; E[Zookeeper] Ensuring High Reliability Kafka’s high reliability stems from its robust replication mechanism, which ensures message availability even in the event of broker failures. Data Synchronization Kafka introduced replication in version 0.8 to mitigate data loss during broker failures. Each partition has multiple replicas, with one replica acting as the leader and others as followers. graph TD A[Producer] --&gt; B[Leader Partition] B --&gt; C[Follower 1] B --&gt; D[Follower 2] C --&gt; E[Write Sync] D --&gt; E[Write Sync] Replica Placement Strategy Kafka distributes replicas across multiple brokers to balance load. It employs a modular arithmetic approach to determine where to place replicas. graph TD A[Broker 1] --&gt; B[Partition 1 Replica 1] A[Broker 2] --&gt; C[Partition 1 Replica 2] A[Broker 3] --&gt; D[Partition 1 Replica 3] Synchronization Strategy Producers only send messages to the leader of a partition. After the leader writes the message, followers synchronize with the leader. graph TD A[Producer] --&gt; B[Leader] B --&gt; C[Follower 1] B --&gt; D[Follower 2] C --&gt; E[ACK] D --&gt; E[ACK] E --&gt; F[Leader Commit] Leader Election Kafka’s leader election is managed by Zookeeper, which uses a distributed lock mechanism to ensure that only one replica becomes the leader of a partition. graph TD A[Zookeeper] --&gt; B[Partition 1 Leader Election] B --&gt; C[Follower 1] B --&gt; D[Follower 2] C --&gt; E[Leader Role] D --&gt; F[Follower Role] Conclusion Kafka’s architecture ensures high reliability, scalability, and performance, making it a vital tool in modern data processing. With its sophisticated replication mechanism, partitioning strategies, and efficient storage system, Kafka delivers message guarantees and fault tolerance that are crucial in large-scale distributed systems. The above content outlines Kafka’s design and operational principles, integrating your provided article with added explanations and visualization using Mermaid diagrams. This should give a clear and comprehensive understanding of Kafka’s message storage, architecture, and reliability features.]]></summary></entry><entry><title type="html">Post: Link</title><link href="http://localhost:4000/blog/post-link/" rel="alternate" type="text/html" title="Post: Link" /><published>2010-03-07T00:00:00+08:00</published><updated>2010-03-07T00:00:00+08:00</updated><id>http://localhost:4000/blog/post-link</id><content type="html" xml:base="http://localhost:4000/blog/post-link/"><![CDATA[<p>This theme supports <strong>link posts</strong>, made famous by John Gruber. To use, just add <code class="language-plaintext highlighter-rouge">link: http://url-you-want-linked</code> to the post’s YAML front matter and you’re done.</p>

<blockquote>
  <p>And this is how a quote looks.</p>
</blockquote>

<p>Some <a href="#">link</a> can also be shown.</p>]]></content><author><name>Madden Zhang</name></author><category term="Blog" /><category term="link" /><category term="Post Formats" /><summary type="html"><![CDATA[This theme supports link posts, made famous by John Gruber. To use, just add link: http://url-you-want-linked to the post’s YAML front matter and you’re done.]]></summary></entry><entry><title type="html">Post: Notice</title><link href="http://localhost:4000/blog/post-notice/" rel="alternate" type="text/html" title="Post: Notice" /><published>2010-02-05T00:00:00+08:00</published><updated>2010-02-05T00:00:00+08:00</updated><id>http://localhost:4000/blog/post-notice</id><content type="html" xml:base="http://localhost:4000/blog/post-notice/"><![CDATA[<p>A notice displays information that explains nearby content. Often used to call attention to a particular detail.</p>

<p>When using Kramdown <code class="language-plaintext highlighter-rouge">{: .notice}</code> can be added after a sentence to assign the <code class="language-plaintext highlighter-rouge">.notice</code> to the <code class="language-plaintext highlighter-rouge">&lt;p&gt;&lt;/p&gt;</code> element.</p>

<p class="notice"><strong>Changes in Service:</strong> We just updated our <a href="#">privacy policy</a> here to better service our customers. We recommend reviewing the changes.</p>

<p class="notice--primary"><strong>Primary Notice:</strong> Lorem ipsum dolor sit amet, consectetur adipiscing elit. Integer nec odio. <a href="#">Praesent libero</a>. Sed cursus ante dapibus diam. Sed nisi. Nulla quis sem at nibh elementum imperdiet.</p>

<p class="notice--info"><strong>Info Notice:</strong> Lorem ipsum dolor sit amet, <a href="#">consectetur adipiscing elit</a>. Integer nec odio. Praesent libero. Sed cursus ante dapibus diam. Sed nisi. Nulla quis sem at nibh elementum imperdiet.</p>

<p class="notice--warning"><strong>Warning Notice:</strong> Lorem ipsum dolor sit amet, consectetur adipiscing elit. <a href="#">Integer nec odio</a>. Praesent libero. Sed cursus ante dapibus diam. Sed nisi. Nulla quis sem at nibh elementum imperdiet.</p>

<p class="notice--danger"><strong>Danger Notice:</strong> Lorem ipsum dolor sit amet, <a href="#">consectetur adipiscing</a> elit. Integer nec odio. Praesent libero. Sed cursus ante dapibus diam. Sed nisi. Nulla quis sem at nibh elementum imperdiet.</p>

<p class="notice--success"><strong>Success Notice:</strong> Lorem ipsum dolor sit amet, consectetur adipiscing elit. Integer nec odio. Praesent libero. Sed cursus ante dapibus diam. Sed nisi. Nulla quis sem at <a href="#">nibh elementum</a> imperdiet.</p>

<p>Want to wrap several paragraphs or other elements in a notice? Using Liquid to capture the content and then filter it with <code class="language-plaintext highlighter-rouge">markdownify</code> is a good way to go.</p>

<div class="language-html highlighter-rouge"><div class="highlight"><pre class="highlight"><code>{% capture notice-2 %}
#### New Site Features

* You can now have cover images on blog pages
* Drafts will now auto-save while writing
{% endcapture %}

<span class="nt">&lt;div</span> <span class="na">class=</span><span class="s">"notice"</span><span class="nt">&gt;</span>{{ notice-2 | markdownify }}<span class="nt">&lt;/div&gt;</span>
</code></pre></div></div>

<div class="notice">
  
<h4 id="new-site-features">New Site Features</h4>

<ul>
  <li>You can now have cover images on blog pages</li>
  <li>Drafts will now auto-save while writing</li>
</ul>

</div>

<p>Or you could skip the capture and stick with straight HTML.</p>

<div class="language-html highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nt">&lt;div</span> <span class="na">class=</span><span class="s">"notice"</span><span class="nt">&gt;</span>
  <span class="nt">&lt;h4&gt;</span>Message<span class="nt">&lt;/h4&gt;</span>
  <span class="nt">&lt;p&gt;</span>A basic message.<span class="nt">&lt;/p&gt;</span>
<span class="nt">&lt;/div&gt;</span>
</code></pre></div></div>

<div class="notice">
  <h4>Message</h4>
  <p>A basic message.</p>
</div>]]></content><author><name>Madden Zhang</name></author><category term="Blog" /><category term="Post Formats" /><category term="notice" /><summary type="html"><![CDATA[A notice displays information that explains nearby content. Often used to call attention to a particular detail.]]></summary></entry><entry><title type="html">Post: Quote</title><link href="http://localhost:4000/blog/post-quote/" rel="alternate" type="text/html" title="Post: Quote" /><published>2010-02-05T00:00:00+08:00</published><updated>2010-02-05T00:00:00+08:00</updated><id>http://localhost:4000/blog/post-quote</id><content type="html" xml:base="http://localhost:4000/blog/post-quote/"><![CDATA[<blockquote>
  <p>Only one thing is impossible for God: To find any sense in any copyright law on the planet.</p>
</blockquote>

<blockquote>
  <p><cite><a href="http://www.brainyquote.com/quotes/quotes/m/marktwain163473.html">Mark Twain</a></cite></p>
</blockquote>]]></content><author><name>Madden Zhang</name></author><category term="Blog" /><category term="Post Formats" /><category term="quote" /><summary type="html"><![CDATA[Only one thing is impossible for God: To find any sense in any copyright law on the planet. Mark Twain]]></summary></entry><entry><title type="html">Post: Chat</title><link href="http://localhost:4000/blog/post-chat/" rel="alternate" type="text/html" title="Post: Chat" /><published>2010-01-08T00:00:00+08:00</published><updated>2010-01-08T00:00:00+08:00</updated><id>http://localhost:4000/blog/post-chat</id><content type="html" xml:base="http://localhost:4000/blog/post-chat/"><![CDATA[<p>Abbott: Strange as it may seem, they give ball players nowadays very peculiar names.</p>

<p>Costello: Funny names?</p>

<p>Abbott: Nicknames, nicknames. Now, on the St. Louis team we have Who’s on first, What’s on second, I Don’t Know is on third–</p>

<p>Costello: That’s what I want to find out. I want you to tell me the names of the fellows on the St. Louis team.</p>

<p>Abbott: I’m telling you. Who’s on first, What’s on second, I Don’t Know is on third–</p>

<p>Costello: You know the fellows’ names?</p>

<p>Abbott: Yes.</p>

<p>Costello: Well, then who’s playing first?</p>

<p>Abbott: Yes.</p>

<p>Costello: I mean the fellow’s name on first base.</p>

<p>Abbott: Who.</p>

<p>Costello: The fellow playin’ first base.</p>

<p>Abbott: Who.</p>

<p>Costello: The guy on first base.</p>

<p>Abbott: Who is on first.</p>

<p>Costello: Well, what are you askin’ me for?</p>

<p>Abbott: I’m not asking you–I’m telling you. Who is on first.</p>

<p>Costello: I’m asking you–who’s on first?</p>

<p>Abbott: That’s the man’s name.</p>

<p>Costello: That’s who’s name?</p>

<p>Abbott: Yes.</p>

<p>Costello: When you pay off the first baseman every month, who gets the money?</p>

<p>Abbott: Every dollar of it. And why not, the man’s entitled to it.</p>

<p>Costello: Who is?</p>

<p>Abbott: Yes.</p>

<p>Costello: So who gets it?</p>

<p>Abbott: Why shouldn’t he? Sometimes his wife comes down and collects it.</p>

<p>Costello: Who’s wife?</p>

<p>Abbott: Yes. After all, the man earns it.</p>

<p>Costello: Who does?</p>

<p>Abbott: Absolutely.</p>

<p>Costello: Well, all I’m trying to find out is what’s the guy’s name on first base?</p>

<p>Abbott: Oh, no, no. What is on second base.</p>

<p>Costello: I’m not asking you who’s on second.</p>

<p>Abbott: Who’s on first!</p>

<p>Costello: St. Louis has a good outfield?</p>

<p>Abbott: Oh, absolutely.</p>

<p>Costello: The left fielder’s name?</p>

<p>Abbott: Why.</p>

<p>Costello: I don’t know, I just thought I’d ask.</p>

<p>Abbott: Well, I just thought I’d tell you.</p>

<p>Costello: Then tell me who’s playing left field?</p>

<p>Abbott: Who’s playing first.</p>

<p>Costello: Stay out of the infield! The left fielder’s name?</p>

<p>Abbott: Why.</p>

<p>Costello: Because.</p>

<p>Abbott: Oh, he’s center field.</p>

<p>Costello: Wait a minute. You got a pitcher on this team?</p>

<p>Abbott: Wouldn’t this be a fine team without a pitcher?</p>

<p>Costello: Tell me the pitcher’s name.</p>

<p>Abbott: Tomorrow.</p>

<p>Costello: Now, when the guy at bat bunts the ball–me being a good catcher–I want to throw the guy out at first base, so I pick up the ball and throw it to who?</p>

<p>Abbott: Now, that’s he first thing you’ve said right.</p>

<p>Costello: I DON’T EVEN KNOW WHAT I’M TALKING ABOUT!</p>

<p>Abbott: Don’t get excited. Take it easy.</p>

<p>Costello: I throw the ball to first base, whoever it is grabs the ball, so the guy runs to second. Who picks up the ball and throws it to what. What throws it to I don’t know. I don’t know throws it back to tomorrow–a triple play.</p>

<p>Abbott: Yeah, it could be.</p>

<p>Costello: Another guy gets up and it’s a long ball to center.</p>

<p>Abbott: Because.</p>

<p>Costello: Why? I don’t know. And I don’t care.</p>

<p>Abbott: What was that?</p>

<p>Costello: I said, I DON’T CARE!</p>

<p>Abbott: Oh, that’s our shortstop!</p>]]></content><author><name>Madden Zhang</name></author><category term="Blog" /><category term="chat" /><category term="Post Formats" /><summary type="html"><![CDATA[Abbott: Strange as it may seem, they give ball players nowadays very peculiar names.]]></summary></entry><entry><title type="html">Post: Modified Date</title><link href="http://localhost:4000/blog/post-modified/" rel="alternate" type="text/html" title="Post: Modified Date" /><published>2010-01-07T00:00:00+08:00</published><updated>2016-03-10T05:20:02+08:00</updated><id>http://localhost:4000/blog/post-modified</id><content type="html" xml:base="http://localhost:4000/blog/post-modified/"><![CDATA[<p>This post has been updated and should show a modified date if used in a layout.</p>

<p>All children, except one, grow up. They soon know that they will grow up, and the way Wendy knew was this. One day when she was two years old she was playing in a garden, and she plucked another flower and ran with it to her mother. I suppose she must have looked rather delightful, for Mrs. Darling put her hand to her heart and cried, “Oh, why can’t you remain like this for ever!” This was all that passed between them on the subject, but henceforth Wendy knew that she must grow up. You always know after you are two. Two is the beginning of the end.</p>]]></content><author><name>Madden Zhang</name></author><category term="Blog" /><category term="Post Formats" /><category term="readability" /><category term="standard" /><summary type="html"><![CDATA[This post has been updated and should show a modified date if used in a layout.]]></summary></entry></feed>